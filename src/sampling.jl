
export sample_priors
sample_priors(planet::Planet) = rand.(planet.priors.priors)
# sample_priors(planet::Planet,N) = rand.(planet.priors.priors,N)
sample_priors(planet::Planet,N) = [sample_priors(planet) for _ in 1:N]

# function sample_priors(planet::ReparameterizedPlanet)
#     sample = NamedTuple(sample_priors(planet.planet))

#     plus = sample.Ï‰ + sample.Î©
#     minus = sample.Ï‰ - sample.Î©
#     reparameterized = merge(
#         delete(sample,  (:Ï‰, :Î©)),
#         (Ï‰Î©âº = plus, Ï‰Î©â»=minus)
#     )
    
#     # Î¦ = sample.Ï‰ + sample.Î© + 2Ï€*sample.Ï„
#     # Î¦Ï‰â» = Î¦ - sample.Ï‰
#     # Î¦Î©â» = Î¦ - sample.Î©
#     # reparameterized = merge(
#     #     delete(sample,  (:Ï„, :Ï‰, :Î©)),
#     #     (;Î¦, Î¦Ï‰â», Î¦Î©â»)
#     # )

#     return ComponentVector(reparameterized)
# end
# function sample_priors(planet::ReparameterizedPlanet, N)
#     sample = NamedTuple(sample_priors(planet.planet, N))
#     plus = sample.Ï‰ .+ sample.Î©
#     minus = sample.Ï‰ .- sample.Î©
#     reparameterized = merge(
#         delete(sample,  (:Ï‰, :Î©)),
#         (Ï‰Î©âº = plus, Ï‰Î©â»=minus)
#     )

#     # Î¦ = sample.Ï‰ .+ sample.Î© .+ 2Ï€*sample.Ï„
#     # Î¦Ï‰â» = Î¦ .- sample.Ï‰
#     # Î¦Î©â» = Î¦ .- sample.Î©
#     # reparameterized = merge(
#     #     delete(sample,  (:Ï„, :Ï‰, :Î©)),
#     #     (;Î¦, Î¦Ï‰â», Î¦Î©â»)
#     # )
#     return ComponentVector(reparameterized)
# end


function sample_priors(system::System)
    sampled = ComponentVector(
        merge(NamedTuple(rand.(system.priors.priors)),
        # (;planets=[sample_priors(planet) for planet in system.planets])
        (;planets=namedtuple(collect(keys(system.planets)), [
            ComponentArray(NamedTuple([k=>v for (k,v) in pairs(NamedTuple(sample_priors(planet)))]))
            for planet in system.planets
        ]))
    ))
    return sampled
end
# function sample_priors(system::System,N)
#     sampled = ComponentVector(
#         merge(NamedTuple(rand.(system.priors.priors,N)),
#         # (;planets=[sample_priors(planet,N) for planet in system.planets])
#         (;planets=[
#             ComponentArray(NamedTuple([k=>v for (k,v) in pairs(NamedTuple(sample_priors(planet,N)))]))
#             for planet in system.planets
#         ])
#     ))
#     return sampled
# end

sample_priors(system::System,N) = [sample_priors(system) for _ in 1:N]



# This function takes a set of parameters and resolves any deterministic variables
resolve_deterministic(system::System{Nothing}, Î¸) = Î¸

# TODO: there should be a more efficient way to do this.
# Worst case, can unroll using (runtime) generated function?
function resolve_deterministic(system::System{<:Deterministic}, Î¸)
    Î¸_resolved = NamedTuple()
    for (key, func) in pairs(system.deterministic.variables)
        val = func(Î¸)
        Î¸_resolved = merge(Î¸_resolved, NamedTuple{(key,), Tuple{eltype(Î¸)}}(val))
    end
    Î¸_resolved = merge(Î¸_resolved, NamedTuple(Î¸))
    # resolved_planets = map(zip(Î¸.planets, system.planets)) do (Î¸_planet, planet_model)
    resolved_planets = map(keys(system.planets)) do key
        Î¸_planet = Î¸.planets[key]
        planet_model = system.planets[key]

        Î¸_planet_resolved = NamedTuple()
        if !isnothing(planet_model.deterministic)
            for (key, func) in pairs(planet_model.deterministic.variables)
                val = func(Î¸_resolved, Î¸_planet)
                Î¸_planet_resolved = merge(Î¸_planet_resolved, NamedTuple{(key,), Tuple{eltype(Î¸)}}(val))
            end
        end
        return merge(Î¸_planet_resolved, NamedTuple(Î¸_planet))
    end
    resolved_planets_nt = namedtuple([pl.name for pl in system.planets], resolved_planets)
    Î¸_resolved = merge(Î¸_resolved, (;planets=resolved_planets_nt))
    return ComponentVector(Î¸_resolved)
end
# function resolve_deterministic!(Î¸_resolved, system::System{<:Deterministic}, Î¸)
#     for (key, func) in pairs(system.deterministic.variables)
#         val = func(Î¸)
#         Î¸_resolved[key] = val 
#     end
#     return Î¸_resolved
# end

# # Version for filling out chains instead of a single set of parameters
# function resolve_deterministic_array(system::System{<:Deterministic}, Î¸s)
#     Î¸_resolved = NamedTuple()
#     # s = length(getproperty(Î¸s, first(keys(Î¸s))))
#     Î¸0 = sample_priors(system)
#     s = length(Î¸0)
#     for (key, func) in pairs(system.deterministic.variables)
#         vals = map(eachrow(reshape(Î¸s, :, s))) do row
#             Î¸_cv = ComponentArray(row, getaxes(Î¸0))
#             Î¸_res = DirectDetections.resolve_deterministic(system, Î¸_cv)
#             func(Î¸_res)
#         end
#         Î¸_resolved = merge(Î¸_resolved, NamedTuple{(key,)}((vals,)))
#     end
#     Î¸_resolved = merge(Î¸_resolved,NamedTuple(Î¸s))
    
#     resolved_planets = map(zip(Î¸_resolved.planets, system.planets)) do (Î¸_planet, planet_model)
#         Î¸_planet_resolved = NamedTuple(Î¸_planet)


#         for (key, func) in pairs(planet_model.deterministic.variables)
#             vals = map(eachrow(reshape(Î¸s, :, s))) do row
#                 Î¸_cv = ComponentArray(row, getaxes(Î¸0))
#                 Î¸_res = DirectDetections.resolve_deterministic(system, Î¸_cv)
#                 func(Î¸_res)
#             end
#             Î¸_resolved = merge(Î¸_resolved, NamedTuple{(key,)}((vals,)))
#         end


#         for (key, func) in pairs(planet_model.deterministic.variables)
#             val = func(Î¸_resolved, Î¸_planet)
#             Î¸_planet_resolved = merge(Î¸_planet_resolved, NamedTuple{(key,), Tuple{eltype(Î¸)}}(val))
#         end
#         return Î¸_planet_resolved
#     end
#     Î¸_resolved = merge(Î¸_resolved, (;planets=resolved_planets))

#     return ComponentVector(Î¸_resolved)
# end


# # Version for filling out chains instead of a single set of parameters
# function resolve_deterministic_chains(system::System{<:Deterministic}, Î¸s)
#     Î¸_resolved = NamedTuple()
#     # s = length(getproperty(Î¸s, first(keys(Î¸s))))
#     Î¸0 = sample_priors(system)

#     first_var = Symbol(first(labels(Î¸0)))

#     # Resolve each variable one at a time, appending the column to the chain structure.
#     for (key, func) in pairs(system.deterministic.variables)

#         # Go through each sample index
#         vals = map(eachindex(Î¸s[first_var])) do i
#         # vals = map(getdata(Î¸s)) do row
#             row = getindex.(getdata(Î¸s), i)

#             Î¸_cv = ComponentArray(row, getaxes(Î¸0))
#             Î¸_res = DirectDetections.resolve_deterministic(system, Î¸_cv)
#             func(Î¸_res)

#         end
#         Î¸_resolved = merge(Î¸_resolved, NamedTuple{(key,)}((vals,)))
#     end
#     Î¸_resolved = merge(Î¸_resolved,NamedTuple(Î¸s))
#     return ComponentVector(Î¸_resolved)
# end


## Okay, still worming out big problems with resolveing the determistic variables
# into the chains at the end of the sampling. I got this working for what gets
# returned by sample_priors(sys, N) but not what gets returns by hmc... What's the difference?
# Must be relying on internal storage
# Priors is one big array.
# chains are vector of "vectors" (not exactly, but close)


# Instead of just calling mean for the distributions, we sample and then take the mean of the data.
# This does add a little jitter, but some distributions do not directly define the mean function!
# Specifically, truncated(InverseGamma()) does not work, and this is very useful.
# mean_priors(planet::Planet) = Statistics.mean.(Statistics.rand.(planet.priors.priors,1000))
function mean_priors(system::System)
    priors_all = ComponentVector(;
        NamedTuple(system.priors.priors)...,
        planets=[planet.priors.priors for planet in system.planets]
    )
    # return Statistics.mean.(Statistics.rand.(priors_all,1000))
    return Statistics.mean.(priors_all)
end
# mean_priors(planet::Planet) = Statistics.mean.(Statistics.rand.(planet.priors.priors,1000))
# function mean_priors(system::System)
#     N = 5000
#     sampled = ComponentVector(
#         merge(NamedTuple(mean.(rand.(system.priors.priors,N))),
#         # (;planets=[mean.(sample_priors(planet,N)) for planet in system.planets])
#         (;planets=[
#             ComponentArray(NamedTuple([k=>mean(v) for (k,v) in pairs(NamedTuple(sample_priors(planet,N)))]))
#             for planet in system.planets
#         ])
#     ))
#     return sampled
# end


function guess_starting_position(system, N=500_000)

    @info "Guessing a good starting location by sampling from priors" N
    # TODO: this shouldn't have to allocate anything, we can just loop keeping the best.
    Î¸ = sample_priors(system, N)
    Î¸r = resolve_deterministic.(system, Î¸)

    # ax = getaxes(Î¸0)
    # axr = getaxes(Î¸0r)

    # l = length(Î¸0)
    # lr = length(Î¸0r)
    # Ar = reshape(getdata(Î¸r), :, lr)
    # posts = zeros(size(Ar,1))
    posts = zeros(N)
    Threads.@threads for i in eachindex(posts)
        # posts[i] = DirectDetections.ln_post(ComponentVector(view(A,i,:), ax), system)
        posts[i] = DirectDetections.ln_post(Î¸r[i], system)
    end
    # posts = map(eachrow(A)) do c
    #     DirectDetections.ln_post(ComponentVector(c, ax), system)
    # end
    mapv,mapi = findmax(posts)
    best = Î¸[mapi]
    
    @info "Found good location" mapv best=NamedTuple(best)

    return best
end


using Optim
function find_starting_position(system)

    initial = guess_starting_position(system, 10_000)

    ax = getaxes(initial)
    function objective(Î¸_dat)
        Î¸ = ComponentArray(Î¸_dat, ax)
        return -DirectDetections.ln_post(Î¸, system)
    end
    
    result = optimize(objective, getdata(initial), GradientDescent(), Optim.Options(show_trace=true, show_every=1000, iterations=100_000), autodiff=:forward)

    display(result)

    best = ComponentArray(Optim.minimizer(result), ax)
    
    @info "Found good location" a=getproperty.(best.planets, :a)

    return best
end



function get_Ï‰Î©Ï„(Î¸_system, Î¸_planet)
    if haskey(Î¸_planet, :Ï‰Î©âº)
        
        # Derivation:
        # Ï‰Î©âº = Ï‰+Î©
        # Ï‰Î©â» = Ï‰-Î©
        # Ï‰Î©âº + Ï‰Î©â» = Ï‰+Î© + Ï‰-Î© = Ï‰
        # Ï‰Î©âº - Ï‰Î©â» = Ï‰+Î© - Ï‰+Î© = Î©
        Ï‰ = Î¸_planet.Ï‰Î©âº + Î¸_planet.Ï‰Î©â» 
        Î© = Î¸_planet.Ï‰Î©âº - Î¸_planet.Ï‰Î©â»
        Ï„ = Î¸_planet.Ï„
    elseif haskey(Î¸_planet, :Î¦)
    
        # Î¦ = sample.Ï‰ .+ sample.Î© .+ 2Ï€*sample.Ï„
        # Î¦Ï‰â» = Î¦ .- sample.Ï‰
        # Î¦Î©â» = Î¦ .- sample.Î©
    
        Ï„2pi = Î¸_planet.Î¦ + Î¸_planet.Î¦Ï‰â» + Î¸_planet.Î¦Î©â»
        Ï‰ = Î¸_planet.Î¦ - Ï„2pi + Î¸_planet.Î¦Î©â»
        Î© = Î¸_planet.Î¦ - Ï„2pi + Î¸_planet.Î¦Ï‰â»
        Ï„ = Ï„2pi/2Ï€

    else
        Ï‰ = Î¸_planet.Ï‰
        Ï„ = Î¸_planet.Ï„

        
        if hasproperty(Î¸_planet,:Î©)
            Î© = Î¸_planet.Î©
        elseif hasproperty(Î¸_system,:Î©)
            Î© = Î¸_system.Î©
        else
            error("property `Î©` not specified for planet or system")
        end
    end
    return Ï‰, Î©, Ï„
end


function construct_elements(Î¸_system, Î¸_planet)
    return KeplerianElements((;
        Î¸_system.Î¼,
        Î¸_system.plx,
        Î¸_planet.i,
        Î¸_planet.Î©,
        Î¸_planet.Ï‰,
        Î¸_planet.e,
        Î¸_planet.Ï„,
        Î¸_planet.a,
    ))
end
function construct_elements(Î¸_system, Î¸_planet, i)
    return KeplerianElements((;
        Î¼=Î¸_system.Î¼[i],
        plx=Î¸_system.plx[i],
        i=Î¸_planet.i[i],
        Î©=Î¸_planet.Î©[i],
        Ï‰=Î¸_planet.Ï‰[i],
        e=Î¸_planet.e[i],
        Ï„=Î¸_planet.Ï„[i],
        a=Î¸_planet.a[i],
    ))
end


function mcmc(
    system::System;
    burnin,
    numwalkers,
    numsamples_perwalker,
    thinning = 1,
    squash = true,
)
    ln_post(Î¸) = ln_prior(Î¸, system) + ln_like(Î¸, system)
 
    # ln_prior_system_specialized = make_ln_prior(Î¸, system)
    # ln_post(Î¸) = ln_prior_system_specialized(Î¸, system) + ln_like(Î¸, system)

    @info "Finding starting point"
    # initial_walkers = find_starting_walkers(ln_post, priors, numwalkers)
    initial_walkers = [sample_priors(system) for _ in 1:numwalkers]

    # Convert the initial walkers into static arrays for stack allocation.
    # This messy line should have no impact on the semantics of the code.
    initial_walkers_static = [
        ComponentVector{SVector{length(cv)}}(; NamedTuple(cv)...) for cv in initial_walkers
    ]

    # Run the MCMC
    thetase, _accept_ratioe = KissMCMC.emcee(
        ln_post,
        initial_walkers_static;
        nburnin = burnin * numwalkers,
        use_progress_meter = true,
        nthin = thinning,
        niter = numsamples_perwalker * numwalkers,
    )

    # Convert the output into an MCMCChains.Chain.
    # Use reinterpret to avoid re-allocating all that memory
    if squash
        thetaseâ€², _ = KissMCMC.squash_walkers(thetase, _accept_ratioe)
        reinterptted = reinterpret(reshape, eltype(first(thetaseâ€²)), thetaseâ€²)
        chains = ComponentArray(collect(eachrow(reinterptted)), getaxes(thetaseâ€²[1]))
    else
        matrix_paramxstep_per_walker = [reinterpret(reshape, eltype(first(Î¸)), Î¸) for Î¸ in thetase]
        A = reshape(
            mapreduce(Î¸->reinterpret(reshape, eltype(first(Î¸)), Î¸), hcat, thetase),
            (length(thetase[1][1]), :, numwalkers,)
        )
        ax = getaxes(thetase[1][1])
        chains = ComponentArray(collect(eachslice(A,dims=1)), ax)
    end

    # return Chains(reinterptted, column_names)
    return chains
end

"""
Given a component vector and a matching component vector that is a boolean mask,
return only the values that are true
"""
function select_cv(cv, mask)
    dat = getdata(cv)
    ax = getaxes(cv)
    dat, ax
    # ComponentArray(dat[mask],ax[1][mask])
    ax[1][mask]
end


# using Zygote
# https://github.com/FluxML/Zygote.jl/issues/570
# @Zygote.adjoint (T::Type{<:SArray})(x::Number...) = T(x...), y->(nothing, y...)
function hmc(
    system::System, target_accept=0.85;
    adaptation,
    iterations,
    tree_depth=10,
    include_adapataion=false,
    initial_samples=100_000,
    initial_parameters=nothing,
)

    # Choose parameter dimensionality and initial parameter value
    initial_Î¸_0 = sample_priors(system)
    D = length(initial_Î¸_0)

    # AdvancedHMC doesn't play well with component arrays by default, so we pass in just the underlying data
    # array and reconstruct the component array on each invocation (this get's compiled out, no perf affects)
    ax = getaxes(initial_Î¸_0)
    # Capture the axis into the closure for performance via the let binding.
    â„“Ï€ = let ax=ax, system=system
        function (Î¸)
            Î¸_cv = ComponentArray(Î¸, ax)

            Î¸_res = resolve_deterministic(system, Î¸_cv, )

            # Correct fixed parameters
            # Î¸_cv_merged = Î¸_cv .* notfixed .+ initial_Î¸_0 .* fixed

            # TODO: verify that this is still a static array
            # ll = ln_post(Î¸_cv_merged, system)

            ll = ln_post(Î¸_res, system)

            return ll
        end
    end

    # â„“Ï€_grad = let ax=ax, system=system, initial_Î¸_0=initial_Î¸_0, fixed=fixed, notfixed = .! fixed
    #     f(Î¸) = ln_post(Î¸, system)
    #     function (Î¸)
    #         Î¸_cv = ComponentArray(Î¸, ax)

    #         # Correct fixed parameters
    #         Î¸_cv_merged = Î¸_cv .* notfixed .+ initial_Î¸_0 .* fixed

    #         # TODO: verify that this is still a static array
    #         ll = ln_post(Î¸_cv_merged, system)

    #         ll_grad = FiniteDiff.finite_difference_gradient(f,Î¸_cv_merged)

    #         return ll, getdata(ll_grad)
    #     end
    # end


    if isnothing(initial_parameters)
        initial_Î¸_cv = guess_starting_position(system,initial_samples)
    else
        initial_Î¸_cv = initial_parameters
    end

    # Use a static comopnent array for efficiency
    # initial_Î¸ = ComponentVector{SVector{length(initial_Î¸_cv)}}(; NamedTuple(initial_Î¸_cv)...)
    initial_Î¸ = initial_Î¸_cv

    # Define a Hamiltonian system
    metric = DenseEuclideanMetric(D)
    # metric = DiagEuclideanMetric(D)
    hamiltonian = Hamiltonian(metric, â„“Ï€, ForwardDiff)
    # hamiltonian = Hamiltonian(metric, â„“Ï€, â„“Ï€_grad)

    initial_Ïµ = find_good_stepsize(hamiltonian, getdata(initial_Î¸))
    # initial_Ïµ = 0.005

    integrator = Leapfrog(initial_Ïµ)
    # 1.05 improves the sampling over standard leapfrog, but 4.0 is too much. It just stays stuck.
    # 1.5 seems better but seems to favour certain trajectories.
    # integrator = TemperedLeapfrog(initial_Ïµ, 1.05)
    proposal = NUTS(integrator, max_depth=tree_depth) 


    # # We have change some parameters when running with image data
    if !isnothing(system.images) && target_accept > 0.6
        target_accept = 0.6
        @info "Sampling from images, lowering target_accept to 0.6"
    end

    adaptor = StanHMCAdaptor(MassMatrixAdaptor(metric), StepSizeAdaptor(target_accept, integrator)) 
    # adaptor = MassMatrixAdaptor(metric)

    logger = SimpleLogger(stdout, Logging.Error)
    samples, stat = with_logger(logger) do
        sample(
            hamiltonian,
            proposal,
            getdata(initial_Î¸),
            iterations,
            adaptor,
            adaptation;
            progress=true,
            drop_warmup=!(adaptor isa AdvancedHMC.NoAdaptation) || include_adapataion
        )
    end

    # sample_grid = reduce(hcat, samples);
    # chain = ComponentArray(collect(eachrow(sample_grid)), ax)

    chain = map(samples) do sample
        ComponentArray(sample, ax)
    end

    # Resolve any computed properties so that the chains contain sampled variables, and deterministic variables.
    # This is to ease analysis. If it becomes too slow down the line, we could put this behind a flag.
    # chain_res = resolve_deterministic_chains(system, chain)
    chain_res = resolve_deterministic.(system, chain)
        
    return chain_res, stat
end


export result2mcmcchain
using MCMCChains: Chains
function result2mcmcchain(system, chains_in)
    # There is a specific column name convention used by MCMCChains to indicate
    # that multiple parameters form a group. Instead of planets.X.a, we adapt our to X[a] 
    # accordingly
    flattened_labels = replace.(labels(first(chains_in)), r"planets\.([^\.]+).([^\.]+)" => s"\1[\2]")
    c = Chains(
        reduce(vcat, getdata.(chains_in)'),
        flattened_labels
    )
end


using TransformVariables
# using Zygote
# https://github.com/FluxML/Zygote.jl/issues/570
# @Zygote.adjoint (T::Type{<:SArray})(x::Number...) = T(x...), y->(nothing, y...)
function hmctf(
    system::System, target_accept=0.8;
    numwalkers=1,
    burnin,
    numsamples_perwalker,
    initial_samples=100_000,
    initial_parameters=nothing,
    tree_depth=12
)

    # Choose parameter dimensionality and initial parameter value
    initial_Î¸_0 = sample_priors(system)
    D = length(initial_Î¸_0)

    # List transformations for all supported variables.
    # We then build a TransformVariables object using whichever
    # are actually in use.
    transformations = Dict(
        :Î¼=>asâ„â‚Š,
        :plx=>asâ„â‚Š,

        :a=>asâ„â‚Š,
        :e=>asâ„â‚Š,
        :Ï„=>asð•€,
        :Ï‰=>asâ„,
        :i=>asâ„,
        :Î©=>asâ„,
        :Ï‰Î©âº=>asâ„,
        :Ï‰Î©â»=>asâ„,

        :mass=>as(Real, 0, 16mjup2msol),

        # TODO.. different flux bands? We can get these from the system images!
        :Keck_Lâ€²=>asâ„â‚Š,

        :Ïƒ_iÂ²=>asâ„â‚Š,
        :Ïƒ_Î©Â²=>asâ„â‚Š,
    )

    system_t_nt = map(keys(system.priors.priors)) do k
        return k => transformations[k]
    end |> collect |> namedtuple
    system_t = as(system_t_nt)
    
    if eltype(system.planets) <: ReparameterizedPlanet
        # Do some fixing up for reparameterized planets. TODO: handle this more elegantly.
        planet_t_nt_0 = map(keys(system.planets[1].priors.priors)) do k
            return k => transformations[k]
        end |> collect |> namedtuple
        planet_t_nt_1 = delete(planet_t_nt_0, (:Ï‰, :Î©))
        planet_t_nt_2 = (;Ï‰Î©âº=transformations[:Ï‰Î©âº], Ï‰Î©â»=transformations[:Ï‰Î©â»])
        planet_t_nt = merge(planet_t_nt_1, planet_t_nt_2)
    else
        planet_t_nt = map(keys(system.planets[1].priors.priors)) do k
            return k => transformations[k]
        end |> collect |> namedtuple
    end
    planet_t = as(planet_t_nt)
    @info "Mapping parameters to the following domains" system=system_t_nt planet=planet_t_nt

    function tvinverse(Î¸)
        system = NamedTupleTools.delete(NamedTuple(Î¸), :planets)
        sys = TransformVariables.inverse(system_t, system)
        pl = map(Î¸.planets) do planet
            TransformVariables.inverse(planet_t, NamedTuple(planet))
        end
        ComponentVector([sys; pl...], getaxes(Î¸))
    end
    t = NamedTupleTools.delete(NamedTuple(initial_Î¸_0), :planets)
    function tvtransform(Î¸)
        system = @view Î¸[1:length(t)]
        sys = TransformVariables.transform(system_t, system)
        pl = map(Î¸.planets) do planet
            TransformVariables.transform(planet_t, planet)
        end
        # TODO: this is likely a bottleneck
        ComponentVector([collect(sys); collect.(pl)...], getaxes(Î¸))
    end
    
    # out = tvinverse(initial_Î¸_0)
    # back = tvtransform(out)

    # return out, back

    # AdvancedHMC doesn't play well with component arrays by default, so we pass in just the underlying data
    # array and reconstruct the component array on each invocation (this get's compiled out, no perf affects)
    ax = getaxes(initial_Î¸_0)
    # Capture the axis into the closure for performance via the let binding.
    â„“Ï€ = let ax=ax, system=system, initial_Î¸_0=initial_Î¸_0, fixed=fixed, notfixed = .! fixed
        function (Î¸)
            Î¸_cv = ComponentArray(Î¸, ax)

            # Correct fixed parameters
            Î¸_cv_merged = Î¸_cv .* notfixed .+ initial_Î¸_0 .* fixed

            Î¸_cv_transformed = tvtransform(Î¸_cv_merged)

            # TODO: verify that this is still a static array
            ll = ln_post(Î¸_cv_transformed, system)

            return ll
        end
    end

    # â„“Ï€_grad = let ax=ax, system=system, initial_Î¸_0=initial_Î¸_0, fixed=fixed, notfixed = .! fixed
    #     f(Î¸) = ln_post(Î¸, system)
    #     function (Î¸)
    #         Î¸_cv = ComponentArray(Î¸, ax)

    #         # Correct fixed parameters
    #         Î¸_cv_merged = Î¸_cv .* notfixed .+ initial_Î¸_0 .* fixed

    #         # TODO: verify that this is still a static array
    #         ll = ln_post(Î¸_cv_merged, system)

    #         ll_grad = FiniteDiff.finite_difference_gradient(f,Î¸_cv_merged)

    #         return ll, getdata(ll_grad)
    #     end
    # end

    chains = []
    stats = []
    # Threads.@threads
     for _ in 1:numwalkers
        # initial_Î¸ = sample_priors(system)
        # initial_Î¸_cv = mean_priors(system)
        # initial_Î¸_cv = guess_starting_position(system,100_000)

        if isnothing(initial_parameters)
            initial_Î¸_cv = guess_starting_position(system,initial_samples)
        else
            initial_Î¸_cv = initial_parameters
        end

        # Use a static comopnent array for efficiency
        initial_Î¸ = tvinverse(ComponentVector{SVector{length(initial_Î¸_cv)}}(; NamedTuple(initial_Î¸_cv)...))
        # initial_Î¸ = tvinverse(initial_Î¸_cv)


        # Define a Hamiltonian system
        metric = DenseEuclideanMetric(D)
        hamiltonian = Hamiltonian(metric, â„“Ï€, ForwardDiff)
        # hamiltonian = Hamiltonian(metric, â„“Ï€, â„“Ï€_grad)


        # Define a leapfrog solver, with initial step size chosen heuristically
        # if !isnothing(system.images)
        #     initial_Ïµ = 0.002
        # else
            initial_Ïµ = find_good_stepsize(hamiltonian, getdata(initial_Î¸))
            # initial_Ïµ = 0.002
        # end


        integrator = Leapfrog(initial_Ïµ)
        # 1.05 improves the sampling over standard leapfrog, but 4.0 is too much. It just stays stuck.
        # 1.5 seems better but seems to favour certain trajectories.
        # integrator = TemperedLeapfrog(initial_Ïµ, 1.05)
        proposal = NUTS(integrator, max_depth=tree_depth) # 12


        # # We have change some parameters when running with image data
        # if !isnothing(system.images) && target_accept > 0.4
        #     target_accept = 0.2
        #     @info "Sampling from images, lowering target_accept to 0.2"
        # end

        adaptor = StanHMCAdaptor(MassMatrixAdaptor(metric), StepSizeAdaptor(target_accept, integrator)) 
        # adaptor = MassMatrixAdaptor(metric)

        logger = SimpleLogger(stdout, Logging.Error)
        samples_transformed, stat = with_logger(logger) do
            sample(hamiltonian, proposal, getdata(initial_Î¸), numsamples_perwalker, adaptor, burnin; progress=(numwalkers==1), drop_warmup=!(adaptor isa AdvancedHMC.NoAdaptation))
        end

        @info "Formatting chains for output"

        function tvtransform_out(Î¸)
            sys = collect(TransformVariables.transform(system_t, @view(Î¸[1:2])))
            planet_vars = @view(Î¸[3:end])
            planets = mapreduce(vcat, Iterators.partition(planet_vars, length(planet_t_nt))) do planetvar
                collect(TransformVariables.transform(planet_t,planetvar))
            end
            return vcat(sys, planets)
        end
        samples = map(tvtransform_out, samples_transformed)

        sample_grid = reduce(hcat, samples);
        chain = ComponentArray(collect(eachrow(sample_grid)), ax)

        # notfixed = .! fixed
        # chain_merged = chain .* notfixed .+ initial_Î¸_0' .* fixed
        
        push!(chains,chain)
        push!(stats,stat)
    end
    return chains, stats
end





# using Optim, ForwardDiff

function find_starting_point(ln_post, priors)
    Î¸â‚€ = rand.(priors)
    i = 0
    while !isfinite(ln_post(Î¸â‚€))
        i += 1
        Î¸â‚€ = rand.(priors)
        if i > 1000
            error(
                "Could not find a starting point in the posterior that is finite by drawing from the priors after 1000 attempts",
            )
        end
    end
    return Î¸â‚€

    # goal(Î¸) = -ln_post(Î¸)

    # m = optimize(goal, Î¸â‚€, BFGS(), Optim.Options(show_trace=true,x_tol=-1,g_tol=1e-1,f_tol=-1); autodiff = :forward)
    # # m = optimize(goal, Î¸â‚€, Newton(), Optim.Options(show_trace=true,); autodiff = :forward)
    # # m = optimize(goal, Î¸â‚€, NelderMead(), Optim.Options(show_trace=true,); autodiff = :forward)
    # # m = optimize(goal, Î¸â‚€, Optim.SimulatedAnnealing(), Optim.Options(show_trace=true,iterations=1_000_000); autodiff = :forward)
    # # m = optimize(goal, Î¸â‚€, Optim.ParticleSwarm(), Optim.Options(show_trace=true,iterations=100_000); autodiff = :forward)

    # display(m)
    # return Optim.minimizer(m)

end










# Start walkers in a gaussian ball around the MLE, while ensuring we don't
# step outside the ranges defined by the priors
function find_starting_walkers(ln_post, priors, numwalkers)
    initial_walkers = map(1:numwalkers) do i
        return initial_position = find_starting_point(ln_post, priors)
    end
    #     initial_position
    # end
    #     # # This used to intiialize the walkers in a Gaussian ball around the MAP.
    #     # # But now we just draw starting points randomly from the priors, this isn't needed.
    #     # map(eachindex(initial_position)) do i
    #     #     p = NaN
    #     #     while !(minimum(priors[i]) < p < maximum(priors[i]))
    #     #         p = initial_position[i] + 0.01randn()*initial_position[i]
    #     #     end
    #     #     p
    #     # end
    #     # initial_position .* (1 .+ randn(length(initial_position)))
    # end
    return initial_walkers
end
