
export sample_priors
sample_priors(planet::Planet) = ourrand.(planet.priors.priors)
sample_priors(planet::Planet,N) = ourrand.(planet.priors.priors,N)

priors_fixed(planet::Planet) = typeof.(planet.priors.priors) .<: Real
priors_fixed(planet::ReparameterizedPlanet) = typeof.(planet.planet.priors.priors) .<: Real

function sample_priors(planet::ReparameterizedPlanet)
    sample = NamedTuple(sample_priors(planet.planet))

    plus = sample.Ï‰ + sample.Î©
    minus = sample.Ï‰ - sample.Î©
    reparameterized = merge(
        delete(sample,  (:Ï‰, :Î©)),
        (Ï‰Î©âº = plus, Ï‰Î©â»=minus)
    )
    
    # Î¦ = sample.Ï‰ + sample.Î© + 2Ï€*sample.Ï„
    # Î¦Ï‰â» = Î¦ - sample.Ï‰
    # Î¦Î©â» = Î¦ - sample.Î©
    # reparameterized = merge(
    #     delete(sample,  (:Ï„, :Ï‰, :Î©)),
    #     (;Î¦, Î¦Ï‰â», Î¦Î©â»)
    # )

    return ComponentVector(reparameterized)
end
function sample_priors(planet::ReparameterizedPlanet, N)
    sample = NamedTuple(sample_priors(planet.planet, N))
    plus = sample.Ï‰ .+ sample.Î©
    minus = sample.Ï‰ .- sample.Î©
    reparameterized = merge(
        delete(sample,  (:Ï‰, :Î©)),
        (Ï‰Î©âº = plus, Ï‰Î©â»=minus)
    )

    # Î¦ = sample.Ï‰ .+ sample.Î© .+ 2Ï€*sample.Ï„
    # Î¦Ï‰â» = Î¦ .- sample.Ï‰
    # Î¦Î©â» = Î¦ .- sample.Î©
    # reparameterized = merge(
    #     delete(sample,  (:Ï„, :Ï‰, :Î©)),
    #     (;Î¦, Î¦Ï‰â», Î¦Î©â»)
    # )
    return ComponentVector(reparameterized)
end

ourrand(n::Real) = n
ourrand(n::Real,N) = fill(n,N)
ourrand(d::Any) = rand(d)
ourrand(d::Any,N) = rand(d,N)

function sample_priors(system::System)
    sampled = ComponentVector(
        merge(NamedTuple(ourrand.(system.priors.priors)),
        # (;planets=[sample_priors(planet) for planet in system.planets])
        (;planets=[
            ComponentArray(NamedTuple([k=>v for (k,v) in pairs(NamedTuple(sample_priors(planet)))]))
            for planet in system.planets
        ])
    ))
    return sampled
end
function sample_priors(system::System,N)
    sampled = ComponentVector(
        merge(NamedTuple(ourrand.(system.priors.priors,N)),
        # (;planets=[sample_priors(planet,N) for planet in system.planets])
        (;planets=[
            ComponentArray(NamedTuple([k=>v for (k,v) in pairs(NamedTuple(sample_priors(planet,N)))]))
            for planet in system.planets
        ])
    ))
    return sampled
end
function priors_fixed(system::System)
    sampled = ComponentVector(merge(
        NamedTuple(typeof.(system.priors.priors) .<: Real),
        (;planets=[
            ComponentArray(NamedTuple([k=>v for (k,v) in pairs(NamedTuple(priors_fixed(planet)))]))
            for planet in system.planets
        ])
    ))
    return sampled
end
export mean_priors
# Instead of just calling mean for the distributions, we sample and then take the mean of the data.
# This does add a little jitter, but some distributions do not directly define the mean function!
# Specifically, truncated(InverseGamma()) does not work, and this is very useful.
# mean_priors(planet::Planet) = Statistics.mean.(Statistics.rand.(planet.priors.priors,1000))
# function mean_priors(system::System)
#     priors_all = ComponentVector(;
#         NamedTuple(system.priors.priors)...,
#         planets=[planet.priors.priors for planet in system.planets]
#     )
#     return Statistics.mean.(Statistics.rand.(priors_all,1000))
# end
# mean_priors(planet::Planet) = Statistics.mean.(Statistics.rand.(planet.priors.priors,1000))
function mean_priors(system::System)
    N = 5000
    sampled = ComponentVector(
        merge(NamedTuple(mean.(rand.(system.priors.priors,N))),
        # (;planets=[mean.(sample_priors(planet,N)) for planet in system.planets])
        (;planets=[
            ComponentArray(NamedTuple([k=>mean(v) for (k,v) in pairs(NamedTuple(sample_priors(planet,N)))]))
            for planet in system.planets
        ])
    ))
    return sampled
end


function guess_starting_position(system, N=500_000)

    @info "Guessing a good starting location by sampling from priors" N
    # TODO: this shouldn't have to allocate anything, we can just loop keeping the best.
    Î¸0 = sample_priors(system)
    Î¸ = sample_priors(system, N)
    ax = getaxes(Î¸0)
    l = length(Î¸0)
    A = reshape(getdata(Î¸), :, l)
    posts = zeros(size(A,1))
    Threads.@threads for i in eachindex(posts)
        # posts[i] = DirectDetections.ln_post(ComponentVector(view(A,i,:), ax), system)
        posts[i] = DirectDetections.ln_post(ComponentVector(view(A,i,:), ax), system)
    end
    # posts = map(eachrow(A)) do c
    #     DirectDetections.ln_post(ComponentVector(c, ax), system)
    # end
    mapv,mapi = findmax(posts)
    best = ComponentArray(reshape(getdata(Î¸), :, l)[mapi,:], ax)
    
    @info "Found good location" mapv a=getproperty.(best.planets, :a)

    return best
end


using Optim
function find_starting_position(system)

    initial = guess_starting_position(system, 10_000)

    ax = getaxes(initial)
    function objective(Î¸_dat)
        Î¸ = ComponentArray(Î¸_dat, ax)
        return -DirectDetections.ln_post(Î¸, system)
    end
    
    result = optimize(objective, getdata(initial), GradientDescent(), Optim.Options(show_trace=true, show_every=1000, iterations=100_000), autodiff=:forward)

    display(result)

    best = ComponentArray(Optim.minimizer(result), ax)
    
    @info "Found good location" a=getproperty.(best.planets, :a)

    return best
end



function get_Ï‰Î©Ï„(Î¸_system, Î¸_planet)
    if haskey(Î¸_planet, :Ï‰Î©âº)
        
        # Derivation:
        # Ï‰Î©âº = Ï‰+Î©
        # Ï‰Î©â» = Ï‰-Î©
        # Ï‰Î©âº + Ï‰Î©â» = Ï‰+Î© + Ï‰-Î© = Ï‰
        # Ï‰Î©âº - Ï‰Î©â» = Ï‰+Î© - Ï‰+Î© = Î©
        Ï‰ = Î¸_planet.Ï‰Î©âº + Î¸_planet.Ï‰Î©â» 
        Î© = Î¸_planet.Ï‰Î©âº - Î¸_planet.Ï‰Î©â»
        Ï„ = Î¸_planet.Ï„
    elseif haskey(Î¸_planet, :Î¦)
    
        # Î¦ = sample.Ï‰ .+ sample.Î© .+ 2Ï€*sample.Ï„
        # Î¦Ï‰â» = Î¦ .- sample.Ï‰
        # Î¦Î©â» = Î¦ .- sample.Î©
    
        Ï„2pi = Î¸_planet.Î¦ + Î¸_planet.Î¦Ï‰â» + Î¸_planet.Î¦Î©â»
        Ï‰ = Î¸_planet.Î¦ - Ï„2pi + Î¸_planet.Î¦Î©â»
        Î© = Î¸_planet.Î¦ - Ï„2pi + Î¸_planet.Î¦Ï‰â»
        Ï„ = Ï„2pi/2Ï€

    else
        Ï‰ = Î¸_planet.Ï‰
        Ï„ = Î¸_planet.Ï„

        
        if hasproperty(Î¸_planet,:Î©)
            Î© = Î¸_planet.Î©
        elseif hasproperty(Î¸_system,:Î©)
            Î© = Î¸_system.Î©
        else
            error("property `Î©` not specified for planet or system")
        end
    end
    return Ï‰, Î©, Ï„
end


function construct_elements(Î¸_system, Î¸_planet)
    # Handle re-parameterized models
    Ï‰, Î©, Ï„ = get_Ï‰Î©Ï„(Î¸_system, Î¸_planet)

    if hasproperty(Î¸_planet,:i)
        i = Î¸_planet.i
    elseif hasproperty(Î¸_system,:i)
        i = Î¸_system.i
    else
        error("property `i` not specified for planet or system")
    end

    return KeplerianElements((;
        Î¸_system.Î¼,
        Î¸_system.plx,
        i,
        Î©,
        Ï‰,
        Î¸_planet.e,
        Ï„,
        Î¸_planet.a,
    ))
end
function construct_elements(Î¸_system, Î¸_planet, i)
    # Handle re-parameterized models. See above.
    if haskey(Î¸_planet, :Ï‰Î©âº)
        Ï‰ = Î¸_planet.Ï‰Î©âº[i] + Î¸_planet.Ï‰Î©â»[i]
        Î© = Î¸_planet.Ï‰Î©âº[i] - Î¸_planet.Ï‰Î©â»[i]
        Ï„ = Î¸_planet.Ï„[i]
    elseif haskey(Î¸_planet, :Î¦)
        Ï„2pi = Î¸_planet.Î¦[i] + Î¸_planet.Î¦Ï‰â»[i] + Î¸_planet.Î¦Î©â»[i]
        Ï‰ = Î¸_planet.Î¦[i] - Ï„2pi + Î¸_planet.Î¦Î©â»[i]
        Î© = Î¸_planet.Î¦[i] - Ï„2pi + Î¸_planet.Î¦Ï‰â»[i]
        Ï„ = Ï„2pi/2Ï€
    else
        Ï‰ = Î¸_planet.Ï‰[i]
        if hasproperty(Î¸_planet,:Î©)
            Î© = Î¸_planet.Î©[i]
        elseif hasproperty(Î¸_system,:Î©)
            Î© = Î¸_system.Î©[i]
        else
            error("property `Î©` not specified for planet or system")
        end
        Ï„ = Î¸_planet.Ï„[i]
    end
    if hasproperty(Î¸_planet,:i)
        inc = Î¸_planet.i[i]
    elseif hasproperty(Î¸_system,:i)
        inc = Î¸_system.i[i]
    else
        error("property `i` not specified for planet or system")
    end

    return KeplerianElements((;
        Î¼=Î¸_system.Î¼[i],
        plx=Î¸_system.plx[i],
        i=inc,
        Î©,
        Ï‰,
        e=Î¸_planet.e[i],
        Ï„,
        a=Î¸_planet.a[i],
    ))
end


function mcmc(
    system::System;
    burnin,
    numwalkers,
    numsamples_perwalker,
    thinning = 1,
    squash = true,
)
    ln_post(Î¸) = ln_prior(Î¸, system) + ln_like(Î¸, system)
 
    # ln_prior_system_specialized = make_ln_prior(Î¸, system)
    # ln_post(Î¸) = ln_prior_system_specialized(Î¸, system) + ln_like(Î¸, system)

    @info "Finding starting point"
    # initial_walkers = find_starting_walkers(ln_post, priors, numwalkers)
    initial_walkers = [sample_priors(system) for _ in 1:numwalkers]

    # Convert the initial walkers into static arrays for stack allocation.
    # This messy line should have no impact on the semantics of the code.
    initial_walkers_static = [
        ComponentVector{SVector{length(cv)}}(; NamedTuple(cv)...) for cv in initial_walkers
    ]

    # Run the MCMC
    thetase, _accept_ratioe = KissMCMC.emcee(
        ln_post,
        initial_walkers;#initial_walkers_static;
        nburnin = burnin * numwalkers,
        use_progress_meter = true,
        nthin = thinning,
        niter = numsamples_perwalker * numwalkers,
    )

    return thetase

    # Convert the output into an MCMCChains.Chain.
    # # Use reinterpret to avoid re-allocating all that memory
    # if squash
    #     thetaseâ€², _ = KissMCMC.squash_walkers(thetase, _accept_ratioe)
    #     reinterptted = reinterpret(reshape, eltype(first(thetaseâ€²)), thetaseâ€²)
    #     chains = ComponentArray(collect(eachrow(reinterptted)), getaxes(thetaseâ€²[1]))
    # else
    #     matrix_paramxstep_per_walker = [reinterpret(reshape, eltype(first(Î¸)), Î¸) for Î¸ in thetase]
    #     A = reshape(
    #         mapreduce(Î¸->reinterpret(reshape, eltype(first(Î¸)), Î¸), hcat, thetase),
    #         (length(thetase[1][1]), :, numwalkers,)
    #     )
    #     ax = getaxes(thetase[1][1])
    #     chains = ComponentArray(collect(eachslice(A,dims=1)), ax)
    # end

    # return Chains(reinterptted, column_names)
    return chains
end

"""
Given a component vector and a matching component vector that is a boolean mask,
return only the values that are true
"""
function select_cv(cv, mask)
    dat = getdata(cv)
    ax = getaxes(cv)
    dat, ax
    # ComponentArray(dat[mask],ax[1][mask])
    ax[1][mask]
end


# using Zygote
# https://github.com/FluxML/Zygote.jl/issues/570
# @Zygote.adjoint (T::Type{<:SArray})(x::Number...) = T(x...), y->(nothing, y...)
function hmc(
    system::System, target_accept=0.65;
    numwalkers=1,
    burnin,
    numsamples_perwalker,
    initial_samples=100_000,
    initial_parameters=nothing,
    tree_depth=10
)

    # Choose parameter dimensionality and initial parameter value
    initial_Î¸_0 = sample_priors(system)
    fixed = priors_fixed(system)
    D = length(initial_Î¸_0)

    # AdvancedHMC doesn't play well with component arrays by default, so we pass in just the underlying data
    # array and reconstruct the component array on each invocation (this get's compiled out, no perf affects)
    ax = getaxes(initial_Î¸_0)
    # Capture the axis into the closure for performance via the let binding.
    â„“Ï€ = let ax=ax, system=system, initial_Î¸_0=initial_Î¸_0, fixed=fixed, notfixed = .! fixed
        function (Î¸)
            Î¸_cv = ComponentArray(Î¸, ax)

            # Correct fixed parameters
            # Î¸_cv_merged = Î¸_cv .* notfixed .+ initial_Î¸_0 .* fixed

            # TODO: verify that this is still a static array
            # ll = ln_post(Î¸_cv_merged, system)

            ll = ln_post(Î¸_cv, system)
            # ll = ln_prior(Î¸_cv, system)

            return ll
        end
    end

    # â„“Ï€_grad = let ax=ax, system=system, initial_Î¸_0=initial_Î¸_0, fixed=fixed, notfixed = .! fixed
    #     f(Î¸) = ln_post(Î¸, system)
    #     function (Î¸)
    #         Î¸_cv = ComponentArray(Î¸, ax)

    #         # Correct fixed parameters
    #         Î¸_cv_merged = Î¸_cv .* notfixed .+ initial_Î¸_0 .* fixed

    #         # TODO: verify that this is still a static array
    #         ll = ln_post(Î¸_cv_merged, system)

    #         ll_grad = FiniteDiff.finite_difference_gradient(f,Î¸_cv_merged)

    #         return ll, getdata(ll_grad)
    #     end
    # end

    chains = []
    stats = []
    # Threads.@threads
     for _ in 1:numwalkers
        # initial_Î¸ = sample_priors(system)
        # initial_Î¸_cv = mean_priors(system)
        # initial_Î¸_cv = guess_starting_position(system,100_000)

        if isnothing(initial_parameters)
            initial_Î¸_cv = guess_starting_position(system,initial_samples)
        else
            initial_Î¸_cv = initial_parameters
        end

        # Use a static comopnent array for efficiency
        # initial_Î¸ = ComponentVector{SVector{length(initial_Î¸_cv)}}(; NamedTuple(initial_Î¸_cv)...)
        initial_Î¸ = initial_Î¸_cv

        # Define a Hamiltonian system
        metric = DenseEuclideanMetric(D)
        # metric = DiagEuclideanMetric(D)
        hamiltonian = Hamiltonian(metric, â„“Ï€, ForwardDiff)
        # hamiltonian = Hamiltonian(metric, â„“Ï€, â„“Ï€_grad)


        # Define a leapfrog solver, with initial step size chosen heuristically
        # if !isnothing(system.images)
        #     initial_Ïµ = 0.002
        # else
            initial_Ïµ = find_good_stepsize(hamiltonian, getdata(initial_Î¸))
            # initial_Ïµ = 0.001
        # end


        integrator = Leapfrog(initial_Ïµ)
        # 1.05 improves the sampling over standard leapfrog, but 4.0 is too much. It just stays stuck.
        # 1.5 seems better but seems to favour certain trajectories.
        # integrator = TemperedLeapfrog(initial_Ïµ, 1.05)
        proposal = NUTS(integrator, max_depth=tree_depth) 


        # # We have change some parameters when running with image data
        if !isnothing(system.images) && target_accept > 0.6
            target_accept = 0.6
            @info "Sampling from images, lowering target_accept to 0.6"
        end

        adaptor = StanHMCAdaptor(MassMatrixAdaptor(metric), StepSizeAdaptor(target_accept, integrator)) 
        # adaptor = MassMatrixAdaptor(metric)

        logger = SimpleLogger(stdout, Logging.Error)
        samples, stat = with_logger(logger) do
            sample(hamiltonian, proposal, getdata(initial_Î¸), numsamples_perwalker, adaptor, burnin; progress=(numwalkers==1), drop_warmup=!(adaptor isa AdvancedHMC.NoAdaptation))
        end

        sample_grid = reduce(hcat, samples);
        chain = ComponentArray(collect(eachrow(sample_grid)), ax)

        # notfixed = .! fixed
        # chain_merged = chain .* notfixed .+ initial_Î¸_0' .* fixed
        
        push!(chains,chain)
        push!(stats,stat)
    end
    return chains, stats
end


using TransformVariables
# using Zygote
# https://github.com/FluxML/Zygote.jl/issues/570
# @Zygote.adjoint (T::Type{<:SArray})(x::Number...) = T(x...), y->(nothing, y...)
function hmctf(
    system::System, target_accept=0.8;
    numwalkers=1,
    burnin,
    numsamples_perwalker,
    initial_samples=100_000,
    initial_parameters=nothing,
    tree_depth=12
)

    # Choose parameter dimensionality and initial parameter value
    initial_Î¸_0 = sample_priors(system)
    fixed = priors_fixed(system)
    D = length(initial_Î¸_0)

    # List transformations for all supported variables.
    # We then build a TransformVariables object using whichever
    # are actually in use.
    transformations = Dict(
        :Î¼=>asâ„â‚Š,
        :plx=>asâ„â‚Š,

        :a=>asâ„â‚Š,
        :e=>asâ„â‚Š,
        :Ï„=>asð•€,
        :Ï‰=>asâ„,
        :i=>asâ„,
        :Î©=>asâ„,
        :Ï‰Î©âº=>asâ„,
        :Ï‰Î©â»=>asâ„,

        :mass=>as(Real, 0, 16mjup2msol),

        # TODO.. different flux bands? We can get these from the system images!
        :Keck_Lâ€²=>asâ„â‚Š,

        :Ïƒ_iÂ²=>asâ„â‚Š,
        :Ïƒ_Î©Â²=>asâ„â‚Š,
    )

    system_t_nt = map(keys(system.priors.priors)) do k
        return k => transformations[k]
    end |> collect |> namedtuple
    system_t = as(system_t_nt)
    
    if eltype(system.planets) <: ReparameterizedPlanet
        # Do some fixing up for reparameterized planets. TODO: handle this more elegantly.
        planet_t_nt_0 = map(keys(system.planets[1].priors.priors)) do k
            return k => transformations[k]
        end |> collect |> namedtuple
        planet_t_nt_1 = delete(planet_t_nt_0, (:Ï‰, :Î©))
        planet_t_nt_2 = (;Ï‰Î©âº=transformations[:Ï‰Î©âº], Ï‰Î©â»=transformations[:Ï‰Î©â»])
        planet_t_nt = merge(planet_t_nt_1, planet_t_nt_2)
    else
        planet_t_nt = map(keys(system.planets[1].priors.priors)) do k
            return k => transformations[k]
        end |> collect |> namedtuple
    end
    planet_t = as(planet_t_nt)
    @info "Mapping parameters to the following domains" system=system_t_nt planet=planet_t_nt

    function tvinverse(Î¸)
        system = NamedTupleTools.delete(NamedTuple(Î¸), :planets)
        sys = TransformVariables.inverse(system_t, system)
        pl = map(Î¸.planets) do planet
            TransformVariables.inverse(planet_t, NamedTuple(planet))
        end
        ComponentVector([sys; pl...], getaxes(Î¸))
    end
    t = NamedTupleTools.delete(NamedTuple(initial_Î¸_0), :planets)
    function tvtransform(Î¸)
        system = @view Î¸[1:length(t)]
        sys = TransformVariables.transform(system_t, system)
        pl = map(Î¸.planets) do planet
            TransformVariables.transform(planet_t, planet)
        end
        # TODO: this is likely a bottleneck
        ComponentVector([collect(sys); collect.(pl)...], getaxes(Î¸))
    end
    
    # out = tvinverse(initial_Î¸_0)
    # back = tvtransform(out)

    # return out, back

    # AdvancedHMC doesn't play well with component arrays by default, so we pass in just the underlying data
    # array and reconstruct the component array on each invocation (this get's compiled out, no perf affects)
    ax = getaxes(initial_Î¸_0)
    # Capture the axis into the closure for performance via the let binding.
    â„“Ï€ = let ax=ax, system=system, initial_Î¸_0=initial_Î¸_0, fixed=fixed, notfixed = .! fixed
        function (Î¸)
            Î¸_cv = ComponentArray(Î¸, ax)

            # Correct fixed parameters
            Î¸_cv_merged = Î¸_cv .* notfixed .+ initial_Î¸_0 .* fixed

            Î¸_cv_transformed = tvtransform(Î¸_cv_merged)

            # TODO: verify that this is still a static array
            ll = ln_post(Î¸_cv_transformed, system)

            return ll
        end
    end

    # â„“Ï€_grad = let ax=ax, system=system, initial_Î¸_0=initial_Î¸_0, fixed=fixed, notfixed = .! fixed
    #     f(Î¸) = ln_post(Î¸, system)
    #     function (Î¸)
    #         Î¸_cv = ComponentArray(Î¸, ax)

    #         # Correct fixed parameters
    #         Î¸_cv_merged = Î¸_cv .* notfixed .+ initial_Î¸_0 .* fixed

    #         # TODO: verify that this is still a static array
    #         ll = ln_post(Î¸_cv_merged, system)

    #         ll_grad = FiniteDiff.finite_difference_gradient(f,Î¸_cv_merged)

    #         return ll, getdata(ll_grad)
    #     end
    # end

    chains = []
    stats = []
    # Threads.@threads
     for _ in 1:numwalkers
        # initial_Î¸ = sample_priors(system)
        # initial_Î¸_cv = mean_priors(system)
        # initial_Î¸_cv = guess_starting_position(system,100_000)

        if isnothing(initial_parameters)
            initial_Î¸_cv = guess_starting_position(system,initial_samples)
        else
            initial_Î¸_cv = initial_parameters
        end

        # Use a static comopnent array for efficiency
        initial_Î¸ = tvinverse(ComponentVector{SVector{length(initial_Î¸_cv)}}(; NamedTuple(initial_Î¸_cv)...))
        # initial_Î¸ = tvinverse(initial_Î¸_cv)


        # Define a Hamiltonian system
        metric = DenseEuclideanMetric(D)
        hamiltonian = Hamiltonian(metric, â„“Ï€, ForwardDiff)
        # hamiltonian = Hamiltonian(metric, â„“Ï€, â„“Ï€_grad)


        # Define a leapfrog solver, with initial step size chosen heuristically
        # if !isnothing(system.images)
        #     initial_Ïµ = 0.002
        # else
            initial_Ïµ = find_good_stepsize(hamiltonian, getdata(initial_Î¸))
            # initial_Ïµ = 0.002
        # end


        integrator = Leapfrog(initial_Ïµ)
        # 1.05 improves the sampling over standard leapfrog, but 4.0 is too much. It just stays stuck.
        # 1.5 seems better but seems to favour certain trajectories.
        # integrator = TemperedLeapfrog(initial_Ïµ, 1.05)
        proposal = NUTS(integrator, max_depth=tree_depth) # 12


        # # We have change some parameters when running with image data
        # if !isnothing(system.images) && target_accept > 0.4
        #     target_accept = 0.2
        #     @info "Sampling from images, lowering target_accept to 0.2"
        # end

        adaptor = StanHMCAdaptor(MassMatrixAdaptor(metric), StepSizeAdaptor(target_accept, integrator)) 
        # adaptor = MassMatrixAdaptor(metric)

        logger = SimpleLogger(stdout, Logging.Error)
        samples_transformed, stat = with_logger(logger) do
            sample(hamiltonian, proposal, getdata(initial_Î¸), numsamples_perwalker, adaptor, burnin; progress=(numwalkers==1), drop_warmup=!(adaptor isa AdvancedHMC.NoAdaptation))
        end

        @info "Formatting chains for output"

        function tvtransform_out(Î¸)
            sys = collect(TransformVariables.transform(system_t, @view(Î¸[1:2])))
            planet_vars = @view(Î¸[3:end])
            planets = mapreduce(vcat, Iterators.partition(planet_vars, length(planet_t_nt))) do planetvar
                collect(TransformVariables.transform(planet_t,planetvar))
            end
            return vcat(sys, planets)
        end
        samples = map(tvtransform_out, samples_transformed)

        sample_grid = reduce(hcat, samples);
        chain = ComponentArray(collect(eachrow(sample_grid)), ax)

        # notfixed = .! fixed
        # chain_merged = chain .* notfixed .+ initial_Î¸_0' .* fixed
        
        push!(chains,chain)
        push!(stats,stat)
    end
    return chains, stats
end





# using Optim, ForwardDiff

function find_starting_point(ln_post, priors)
    Î¸â‚€ = rand.(priors)
    i = 0
    while !isfinite(ln_post(Î¸â‚€))
        i += 1
        Î¸â‚€ = rand.(priors)
        if i > 1000
            error(
                "Could not find a starting point in the posterior that is finite by drawing from the priors after 1000 attempts",
            )
        end
    end
    return Î¸â‚€

    # goal(Î¸) = -ln_post(Î¸)

    # m = optimize(goal, Î¸â‚€, BFGS(), Optim.Options(show_trace=true,x_tol=-1,g_tol=1e-1,f_tol=-1); autodiff = :forward)
    # # m = optimize(goal, Î¸â‚€, Newton(), Optim.Options(show_trace=true,); autodiff = :forward)
    # # m = optimize(goal, Î¸â‚€, NelderMead(), Optim.Options(show_trace=true,); autodiff = :forward)
    # # m = optimize(goal, Î¸â‚€, Optim.SimulatedAnnealing(), Optim.Options(show_trace=true,iterations=1_000_000); autodiff = :forward)
    # # m = optimize(goal, Î¸â‚€, Optim.ParticleSwarm(), Optim.Options(show_trace=true,iterations=100_000); autodiff = :forward)

    # display(m)
    # return Optim.minimizer(m)

end










# Start walkers in a gaussian ball around the MLE, while ensuring we don't
# step outside the ranges defined by the priors
function find_starting_walkers(ln_post, priors, numwalkers)
    initial_walkers = map(1:numwalkers) do i
        return initial_position = find_starting_point(ln_post, priors)
    end
    #     initial_position
    # end
    #     # # This used to intiialize the walkers in a Gaussian ball around the MAP.
    #     # # But now we just draw starting points randomly from the priors, this isn't needed.
    #     # map(eachindex(initial_position)) do i
    #     #     p = NaN
    #     #     while !(minimum(priors[i]) < p < maximum(priors[i]))
    #     #         p = initial_position[i] + 0.01randn()*initial_position[i]
    #     #     end
    #     #     p
    #     # end
    #     # initial_position .* (1 .+ randn(length(initial_position)))
    # end
    return initial_walkers
end
